# -*- coding: utf-8 -*-
"""ECE1513Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hgtKJfdG_4oVcCvz4oi0cj0_P9vU7-5R

Name: Jing Guo; Student Number:1010136210

Link: https://colab.research.google.com/drive/1hgtKJfdG_4oVcCvz4oi0cj0_P9vU7-5R#scrollTo=FTG7213CpIyH
"""

# load standard modules/libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

# load special modules/libraries
import os
import warnings
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

from collections import Counter
import string
import re
from tqdm  import tqdm

# load pytorch modules/libraries
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset,TensorDataset,DataLoader

from sklearn.metrics import accuracy_score, confusion_matrix, f1_score
import itertools

from google.colab import drive
drive.mount('/content/drive')
drive_content = os.listdir('/content/drive/My Drive/ColabNotebooks/nlp-getting-started')
print(drive_content)

file_path_train = '/content/drive/My Drive/ColabNotebooks/nlp-getting-started/train.csv'
df_train = pd.read_csv(file_path_train)
print('Training Set Shape = {}'.format(df_train.shape))
print('Training Set Memory Usage = {:.2f} MB'.format(df_train.memory_usage().sum() / 1024**2))

df_train.head()

# processi nto data and labels
X = df_train['text'].values
y = df_train['target'].values

# TO BE COMPLETED
positive_indices = np.where(y == 1)[0][:5]
print(X[positive_indices])
print('\n')
negative_indices = np.where(y == 0)[0][:5]
print(X[negative_indices])

# Calculate the character length of positive and negative reviews
df_train['review_char_length'] = df_train['text'].apply(len)

average_char_length = df_train['review_char_length'].mean()
min_char_length = df_train['review_char_length'].min()
max_char_length = df_train['review_char_length'].max()

positive_reviews = df_train[df_train['target'] == 1]
negative_reviews = df_train[df_train['target'] == 0]

average_positive_char_length = positive_reviews['review_char_length'].mean()
average_negtive_char_length = negative_reviews['review_char_length'].mean()

num_positive_reviews = len(positive_reviews)
num_negative_reviews = len(negative_reviews)

# Generate a histogram
plt.figure(figsize=(10, 6))
plt.hist(positive_reviews['review_char_length'], bins=50, alpha=0.5, label='Positive Reviews')
plt.hist(negative_reviews['review_char_length'], bins=50, alpha=0.5, label='Negative Reviews')
plt.axvline(average_char_length, color='red', linestyle='dashed', linewidth=2, label='Average Character Length')
plt.title('Distribution of Character Lengths for Positive and Negative Reviews')
plt.xlabel('Character Length')
plt.ylabel('Frequency')
plt.legend()
plt.show()

# Print result
print(f"Average Character Length of a Review: {average_char_length:.2f} characters")
print(f"Average Character Length of a Positive Review: {average_positive_char_length:.2f}")
print(f"Average Character Length of a Negtive Review: {average_negtive_char_length:.2f}")
print(f"Minimum Character Length: {min_char_length} characters")
print(f"Maximum Character Length: {max_char_length} characters")
print(f"Number of Positive Reviews: {num_positive_reviews}")
print(f"Number of Negative Reviews: {num_negative_reviews}")

# Process the data
# Cleaning a given string stadndardize the words input and remove the non-characteristics.
def preprocess_string(str1):
    # remove all non-word characters excluding number and letters
    str1= re.sub(r"[^\w\s]",'',str1)
    # remove all whitespace with no space
    str1= re.sub(r"\s",'',str1)
    # replace digits with no space
    str1= re.sub(r"\d",'',str1)
    return str1

# Remove stop words
def preprocess_sentence(sen1):
    word_list=[]
    stop_word = set(stopwords.words("english"))
    for word in sen1.lower().split():
        word = preprocess_string(word)
        if word not in stop_word and word!='':
            word_list.append(word)
    return word_list

# Creates a vocabulary that only include the most important words
def get_stoi(data):
    word_list=[]
    for review in data:
        word_list.extend(preprocess_sentence(review))
    corpus = Counter(word_list)
    print(corpus.get)
    # sorting on the basis of most common words
    corpus_ =sorted(corpus,key= corpus.get,reverse=True)[:1000]
    # creating a dict
    stoi =  {ch:i+1 for i,ch in enumerate(corpus_)}
    return stoi

# Tokenize setence
def tokenize(data, labels, stoi):
    # tokenize
    data_encoded = []
    for review in data:
        data_encoded.append([stoi[word] for word in preprocess_sentence(review)
                                     if word in stoi.keys()])
    return np.array(data_encoded), np.array(labels)

# Create uniform length for each review
def padding_(sentences, seq_len):
    features = np.zeros((len(sentences), seq_len),dtype=int)
    for ii, review in enumerate(sentences):
        if len(review)!=0:
            features[ii, -len(review):] = np.array(review)[:seq_len]
    return features

def PreparedTrain(traindatasetX, datasetX, datasety, padding=150):
    # Get vocabulary (stoi) using the training dataset
    stoi = get_stoi(traindatasetX)

    # Tokenize
    datasetX_encoded, datasety_encoded = tokenize(datasetX, datasety, stoi)
    datasetX_padded = padding_(datasetX_encoded, padding)

    return datasetX_padded, datasety_encoded
# Split the dataset into train, validation, and test sets (60/20/20)
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=1)
X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)

# training/validate/test set
X_train_padded, y_train_encoded = PreparedTrain(X_train, X_train, y_train)
X_valid_padded, y_valid_encoded = PreparedTrain(X_train, X_valid, y_valid)
X_test_padded, y_test_encoded = PreparedTrain(X_train, X_test, y_test)

class CustomDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]
train_dataset = CustomDataset(X_train_padded, y_train_encoded)
valid_dataset = CustomDataset(X_valid_padded, y_valid_encoded)
test_dataset = CustomDataset(X_test_padded, y_test_encoded)

batch_size = 16
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)

# Print the size of the dataloader
for batch_idx, (batch_X, batch_y) in enumerate(train_dataloader):
    print(f"Batch Index: {batch_idx}")
    print("Batch X shape:", batch_X.shape)
    print("Batch y shape:", batch_y.shape)
    break
# Print total number of batches
print("Total Batches:", len(train_dataloader))

# RNN Model an embedding layer (with size embedding dim) followed by
# an RNN layer and a fully connected layer.
class SentimentRNNCon(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):
        super(SentimentRNNCon, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.hidden_size = hidden_size
        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size*2, num_classes)

    def forward(self, x):
        x = self.embedding(x)
        h0 = torch.zeros(1, x.size(0), self.hidden_size)
        out, _ = self.rnn(x, h0)
        out = torch.cat([torch.max(out, dim=1)[0],
                 torch.mean(out, dim=1)], dim=1)
        out = self.fc(out)
        return out

# Calculate Accuracy
def get_accuracy(model, data, device='cpu'):
    """ Compute the accuracy of the `model` across a dataset `data` """
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():  # To reduce memory consumption
        for tweets, labels in data:
            tweets, labels = tweets.to(device), labels.to(device)
            output = model(tweets)
            pred = output.max(1, keepdim=True)[1]
            correct += pred.eq(labels.view_as(pred)).sum().item()
            total += labels.shape[0]
    model.train()
    return correct / total

# Calculate F1 Score
def get_f1_score(model, data, device='cpu'):
    """ Compute the F1 score of the `model` across a dataset `data` """
    model.eval()
    true_labels, predicted_labels = [], []

    with torch.no_grad():  # To reduce memory consumption
        for tweets, labels in data:
            tweets, labels = tweets.to(device), labels.to(device)
            output = model(tweets)
            pred = output.max(1, keepdim=True)[1]

            true_labels.extend(labels.cpu().numpy())
            predicted_labels.extend(pred.cpu().numpy().flatten())

    model.train()

    f1 = f1_score(true_labels, predicted_labels)
    return f1

# Train fucntion hyperparameter: learning rate, number of epochs
def train_rnn_networkS(model, train, valid, num_epochs=5, learning_rate=1e-5, device='cpu'):
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    train_losses, valid_losses, train_acc, valid_acc, train_f1, valid_f1 = [], [], [], [], [], []
    epochs = []

    for epoch in range(num_epochs):
        model.train()  # Set model to training mode
        epoch_train_loss = 0.0
        train_preds, train_labels = [], []

        for tweets, labels in train:
            tweets, labels = tweets.to(device), labels.to(device)  # Move to GPU if using

            optimizer.zero_grad()
            pred = model(tweets)
            loss = criterion(pred, labels)
            loss.backward()
            optimizer.step()

            epoch_train_loss += loss.item()

            train_preds.extend(pred.argmax(dim=1).cpu().numpy())
            train_labels.extend(labels.cpu().numpy())

        epoch_train_loss /= len(train)
        train_losses.append(epoch_train_loss)
        epochs.append(epoch)

        train_f1_score = f1_score(train_labels, train_preds, average='macro')
        train_f1.append(train_f1_score)

        # Validation phase
        model.eval()  # Set model to evaluation mode
        epoch_valid_loss = 0.0
        valid_preds, valid_labels = [], []

        with torch.no_grad():
            for tweets, labels in valid:
                tweets, labels = tweets.to(device), labels.to(device)
                output = model(tweets)
                loss = criterion(output, labels)
                epoch_valid_loss += loss.item()

                valid_preds.extend(output.argmax(dim=1).cpu().numpy())
                valid_labels.extend(labels.cpu().numpy())

        epoch_valid_loss /= len(valid)
        valid_losses.append(epoch_valid_loss)

        valid_f1_score = f1_score(valid_labels, valid_preds, average='macro')
        valid_f1.append(valid_f1_score)

        train_acc.append(get_accuracy(model, train, device))
        valid_acc.append(get_accuracy(model, valid, device))

        print(f"Epoch {epoch+1}; Train Loss {epoch_train_loss:.6f}; Valid Loss {epoch_valid_loss:.6f}; "
              f"Train Acc {train_acc[-1]:.6f}; Val Acc {valid_acc[-1]:.6f}; Train F1 {train_f1[-1]:.6f}; Val F1 {valid_f1[-1]:.6f}")

        model_checkpoint_path = '/content/drive/My Drive/ColabNotebooks/new'
        model_checkpoint_file = os.path.join(model_checkpoint_path, f'bestmodel=model_epoch{epoch + 1}')
        torch.save(model.state_dict(), f"{model_checkpoint_file}.pt")
        print(f"Saved model checkpoint: {model_checkpoint_file}")
        torch.cuda.empty_cache()
    # Plotting Loss
    plt.title("Training and Validation Loss")
    plt.plot(epochs, train_losses, label="Train")
    plt.plot(epochs, valid_losses, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend(loc='best')
    plt.show()

    # Plotting Accuracy
    plt.title("Training and Validation Accuracy")
    plt.plot(epochs, train_losses, label="Train")
    plt.plot(epochs, valid_losses, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend(loc='best')
    plt.show()

    # Plotting F1
    plt.title("Training and Validation F1")
    plt.plot(epochs, train_f1, label="Train")
    plt.plot(epochs, valid_f1, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("F1")
    plt.legend(loc='best')
    plt.show()

#  With Maxpooling; Emembedding_dim: 100; hiden layer: 30; learning rate 0.0005
stoi = get_stoi(X_train)
model = SentimentRNNCon(len(stoi)+1,100,30,2)
train_rnn_networkS(model,train_dataloader, valid_dataloader,num_epochs=25, learning_rate=0.0005)

#  With Maxpooling; Emembedding_dim: 100; hiden layer: 20; learning rate 0.0005
model = SentimentRNNCon(len(stoi)+1,80,20,2)
train_rnn_networkS(model,train_dataloader, valid_dataloader,num_epochs=25, learning_rate=0.0005)

#  With Maxpooling; Emembedding_dim: 100; hiden layer: 10; learning rate 0.001
model = SentimentRNNCon(len(stoi)+1,100,10,2)
train_rnn_networkS(model,train_dataloader, valid_dataloader,num_epochs=30, learning_rate=0.001)

# Best RNN
best_model = SentimentRNNCon(len(stoi)+1,100,30,2)
best_model.load_state_dict(torch.load('/content/drive/My Drive/ColabNotebooks/new/bestmodel=model_epoch67885.pt'))

# Final Test result for RNN model
print("Test Acc %f;" % (get_accuracy(best_model, test_dataloader)))
print("Test F1 %f;" % (get_f1_score(best_model, test_dataloader)))

# Bi-direction LSTM model
class SentimentBiLSTM(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):
        super(SentimentBiLSTM, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.hidden_size = hidden_size
        # Use BiLSTM instead of RNN
        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)
        # Adjust the input size of the fully connected layer
        self.fc = nn.Linear(hidden_size * 2 * 2, num_classes)

    def forward(self, x):
        x = self.embedding(x)
        h0 = torch.zeros(2, x.size(0), self.hidden_size)  # Initial hidden state
        c0 = torch.zeros(2, x.size(0), self.hidden_size)  # Initial cell state

        out, _ = self.lstm(x, (h0, c0))
        out = torch.cat([torch.max(out, dim=1)[0], torch.mean(out, dim=1)], dim=1)
        out = self.fc(out)
        return out

#  With Maxpooling; Emembedding_dim: 100; hiden layer: 30; learning rate 0.0005
model1 = SentimentBiLSTM(len(stoi)+1,100,30,2)
train_rnn_networkS(model1,train_dataloader, valid_dataloader,num_epochs=25, learning_rate=0.0005 )

#  With Maxpooling; Emembedding_dim: 200; hiden layer: 30; learning rate 0.0001
model1 = SentimentBiLSTM(len(stoi)+1,200,30,2)
train_rnn_networkS(model1,train_dataloader, valid_dataloader,num_epochs=25, learning_rate=0.0001 )

#  With Maxpooling; Emembedding_dim: 200; hiden layer: 15; learning rate 0.0002
model1 = SentimentBiLSTM(len(stoi)+1,200,15,2)
train_rnn_networkS(model1,train_dataloader, valid_dataloader,num_epochs=28, learning_rate=0.0002 )

#  With Maxpooling; Emembedding_dim: 200; hiden layer: 50; learning rate 0.0002
model1 = SentimentBiLSTM(len(stoi)+1,200,50,2)
train_rnn_networkS(model1,train_dataloader, valid_dataloader,num_epochs=25, learning_rate=0.0002 )

# Best Bi-direction LSTM model
stoi = get_stoi(X_train)
best_modelBi = SentimentBiLSTM(len(stoi)+1,200,30,2)
best_modelBi.load_state_dict(torch.load('/content/drive/My Drive/ColabNotebooks/new/bestmodel=200302model_epoch168089.pt'))

# Final Test result for Bi-direction LSTM model
print("Test Acc %f;" % (get_accuracy(best_modelBi, test_dataloader)))
print("Test F1 %f;" % (get_f1_score(best_modelBi, test_dataloader)))

"""# Transfer Learning Bert Model

"""

# install relevant libraries
!pip install -qq transformers

import transformers
from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup

PRE_TRAINED_MODEL_NAME = 'bert-base-cased'

tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)
bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)

# Process data to remove the non-word characters
def preprocess_string(str1):
    # remove all non-word characters excluding number and letters
    str1= re.sub(r"[^\w\s]",'',str1)
    # remove all whitespace with no space
    str1= re.sub(r"\s",'',str1)
    # replace digits with no space
    str1= re.sub(r"\d",'',str1)
    return str1
def preprocess_sentence(sen1):
    word_list = []
    stop_words = set(stopwords.words("english"))
    for word in sen1.lower().split():
        word = preprocess_string(word)
        if word not in stop_words and word != '' and len(word) > 2 and not word.startswith(("http", "https")):
            word_list.append(word)
    return word_list
def join_words_preprocess(sen1):
    word_list = preprocess_sentence(sen1)
    return ' '.join(word_list)

# Data processing
class MovieReviewDataset(Dataset):

  def __init__(self, reviews, targets, tokenizer, max_len):
    self.reviews = reviews
    self.targets = targets
    self.tokenizer = tokenizer
    self.max_len = max_len

  def __len__(self):
    return len(self.reviews)

  def __getitem__(self, item):
    review = str(self.reviews[item])
    target = self.targets[item]

    encoding = self.tokenizer.encode_plus(
      review,
      add_special_tokens=True,
      max_length=self.max_len,
      return_token_type_ids=False,
      padding='max_length',
      return_attention_mask=True,
      return_tensors='pt',
      truncation=True
    )

    return {
      'review_text': review,
      'input_ids': encoding['input_ids'].flatten(),
      'attention_mask': encoding['attention_mask'].flatten(),
      'targets': torch.tensor(target, dtype=torch.long)
    }

# Apply data processing
df_2 = df_train
df_2['text'] = df_2['text'].apply(join_words_preprocess)

# Calculate the character length of positive and negative reviews
df_2['review_char_length'] = df_train['text'].apply(len)

average_char_length = df_2['review_char_length'].mean()
min_char_length = df_2['review_char_length'].min()
max_char_length = df_2['review_char_length'].max()

positive_reviews = df_2[df_2['target'] == 1]
negative_reviews = df_2[df_2['target'] == 0]

average_positive_char_length = positive_reviews['review_char_length'].mean()
average_negtive_char_length = negative_reviews['review_char_length'].mean()

num_positive_reviews = len(positive_reviews)
num_negative_reviews = len(negative_reviews)

# Print result
print(f"Average Character Length of a Review: {average_char_length:.2f} characters")
print(f"Average Character Length of a Positive Review: {average_positive_char_length:.2f}")
print(f"Average Character Length of a Negtive Review: {average_negtive_char_length:.2f}")
print(f"Minimum Character Length: {min_char_length} characters")
print(f"Maximum Character Length: {max_char_length} characters")
print(f"Number of Positive Reviews: {num_positive_reviews}")
print(f"Number of Negative Reviews: {num_negative_reviews}")

X_pro = df_2['text'].values
y = df_2['target'].values
X_train, X_temp, y_train, y_temp = train_test_split(X_pro, y, test_size=0.7, random_state=1)
X_valid, X_temp2, y_valid, y_temp2 = train_test_split(X_temp, y_temp, test_size=0.9, random_state=1)
X_temp2, X_test, y_temp2, y_test = train_test_split(X_temp, y_temp, test_size=0.88, random_state=1)

# prepare data loaders
MAX_LEN = 138
BATCH_SIZE = 10

#training data
train_data = MovieReviewDataset(reviews=X_train,
                                targets=y_train,
                                tokenizer=tokenizer,
                                max_len=MAX_LEN)

train_data_loader = DataLoader(train_data, batch_size = BATCH_SIZE, num_workers = 1)

#validation data

valid_data = MovieReviewDataset(reviews=X_valid,
                                targets=y_valid,
                                tokenizer=tokenizer,
                                max_len=MAX_LEN)

valid_data_loader = DataLoader(valid_data, batch_size = BATCH_SIZE, num_workers = 1)
#test data

test_data = MovieReviewDataset(reviews=X_test,
                                targets=y_test,
                                tokenizer=tokenizer,
                                max_len=MAX_LEN)

test_data_loader = DataLoader(test_data, batch_size = BATCH_SIZE, num_workers = 1)

# Top words in the review
def get_top_tokens(data_loader, tokenizer, num_tokens=5):
    all_tokens = []
    for batch in data_loader:
        input_ids = batch['input_ids']
        attention_mask = batch['attention_mask']

        # Mask out the PAD tokens before flattening
        input_ids = input_ids[attention_mask == 1]

        all_tokens.extend(input_ids.flatten().numpy())

    token_counts = Counter(all_tokens)

    if tokenizer.pad_token_id in token_counts:
        del token_counts[tokenizer.pad_token_id]

    top_tokens = token_counts.most_common(num_tokens + 50)

    top_tokens_final = []
    for token, count in top_tokens:
        token_str = tokenizer.convert_ids_to_tokens([token])[0]
        # Exclude subwords and specific tokens
        if token_str.startswith(("##", "[")) or len(token_str) < 3:
            continue
        top_tokens_final.append((token_str, count))
    return top_tokens_final[:num_tokens]
top_tokens_train = get_top_tokens(train_data_loader, tokenizer, num_tokens=5)
print("Top 5 occurring tokens in the training dataset:")
for token, count in top_tokens_train:
    print(f"Token: {token}, Count: {count}")

# Bert Model
class SentimentClassifierPooled(nn.Module):
    def __init__(self, hiden_size, n_classes):
        super(SentimentClassifierPooled, self).__init__()
        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)

        # TO BE COMPLETED
        self.dropout = nn.Dropout(p=0.3)
        self.relu = nn.ReLU()
        #self.out = nn.Linear(self.bert.config.hidden_size, n_classes)
        self.fc1 = nn.Linear(768, hiden_size)
        self.fc2 = nn.Linear(hiden_size, n_classes)
        self.name = "SentimentClassifierPooled"

    def forward(self, input_ids, attention_mask):

        pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)[1]
        # TO BE COMPLETED
        output = self.dropout(pooled_output)
        output = self.relu(self.fc1(output))
        output = self.fc2(output)
        output = F.softmax(output, dim=1)
        return output

# Calculate accuracy for Bert Model
def get_accuracy(model, dataset, device='cpu'):
    model.eval()
    correct_predictions = 0
    total_samples = 0
    with torch.no_grad():
        for data in dataset:
            tweets = data['input_ids'].to(device)
            attention_mask = data['attention_mask'].to(device)
            targets = data['targets'].to(device)

            outputs = model(tweets, attention_mask=attention_mask)
            _, predicted = torch.max(outputs, 1)
            correct_predictions += (predicted == targets).sum().item()
            total_samples += targets.size(0)

    accuracy = correct_predictions / total_samples
    model.train()
    return accuracy

# Calculate f1 score for Bert
def get_f1_score(model, dataset, device='cpu'):
    model.eval()
    all_predictions = []
    all_targets = []
    with torch.no_grad():
        for data in dataset:
            tweets = data['input_ids'].to(device)
            attention_mask = data['attention_mask'].to(device)
            targets = data['targets'].to(device)

            outputs = model(tweets, attention_mask=attention_mask)
            _, predicted = torch.max(outputs, 1)

            all_predictions.extend(predicted.cpu().numpy())
            all_targets.extend(targets.cpu().numpy())

    f1 = f1_score(all_targets, all_predictions, average='macro')
    model.train()
    return f1

def train_rnn_network(model, train, valid, num_epochs=5, learning_rate=1e-5, device='cpu'):
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    train_losses, valid_losses, train_acc, valid_acc, train_f1, valid_f1 = [], [], [], [], [], []
    epochs = []

    for epoch in range(num_epochs):
        epoch_train_loss = 0.0
        train_preds, train_labels = [], []

        for batch in train:
            inputs = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            targets = batch['targets'].to(device)

            optimizer.zero_grad()
            outputs = model(inputs, attention_mask)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()

            epoch_train_loss += loss.item()

            train_preds.extend(outputs.argmax(dim=1).cpu().numpy())
            train_labels.extend(targets.cpu().numpy())

        epoch_train_loss /= len(train)
        train_losses.append(epoch_train_loss)
        epochs.append(epoch)

        train_f1_score = f1_score(train_labels, train_preds, average='macro')
        train_f1.append(train_f1_score)

        model.eval()  # Set model to evaluation mode
        epoch_valid_loss = 0.0
        valid_preds, valid_labels = [], []

        with torch.no_grad():
            for batch_v in valid:
                inputs_v = batch_v['input_ids'].to(device)
                attention_mask_v = batch_v['attention_mask'].to(device)
                labels_v = batch_v['targets'].to(device)

                output_v = model(inputs_v, attention_mask_v)
                loss_v = criterion(output_v, labels_v)
                epoch_valid_loss += loss_v.item()

                valid_preds.extend(output_v.argmax(dim=1).cpu().numpy())
                valid_labels.extend(labels_v.cpu().numpy())

        epoch_valid_loss /= len(valid)
        valid_losses.append(epoch_valid_loss)

        valid_f1_score = f1_score(valid_labels, valid_preds, average='macro')
        valid_f1.append(valid_f1_score)

        train_acc.append(get_accuracy(model, train, device))
        valid_acc.append(get_accuracy(model, valid, device))

        print(f"Epoch {epoch+1}; Train Loss {epoch_train_loss:.6f}; Valid Loss {epoch_valid_loss:.6f}; "
              f"Train Acc {train_acc[-1]:.6f}; Val Acc {valid_acc[-1]:.6f}; Train F1 {train_f1[-1]:.6f}; Val F1 {valid_f1[-1]:.6f}")

        model_checkpoint_path = '/content/drive/My Drive/ColabNotebooks/new'
        model_checkpoint_file = os.path.join(model_checkpoint_path, f'bestmodel=model_epoch{epoch + 1}.pth')
        torch.save(model.state_dict(), f"{model_checkpoint_file}.pt")
        print(f"Saved model checkpoint: {model_checkpoint_file}")
        torch.cuda.empty_cache()
    # Plotting Loss
    plt.title("Training and Validation Loss")
    plt.plot(epochs, train_losses, label="Train")
    plt.plot(epochs, valid_losses, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend(loc='best')
    plt.show()

    # Plotting Accuracy
    plt.title("Training and Validation Accuracy")
    plt.plot(epochs, train_acc, label="Train")
    plt.plot(epochs, valid_acc, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend(loc='best')
    plt.show()

    # Plotting F1
    plt.title("Training and Validation F1 score")
    plt.plot(epochs, train_f1, label="Train")
    plt.plot(epochs, valid_f1, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("F1 score")
    plt.legend(loc='best')
    plt.show()

# With hiden layer: 30; learning rate 0.00001
modelS = SentimentClassifierPooled(30,2)
train_rnn_network(modelS,train_data_loader,valid_data_loader,num_epochs=20,learning_rate=0.00001)

# With hiden layer: 20; learning rate 0.005
modelS = SentimentClassifierPooled(20,2)
train_rnn_network(modelS,train_data_loader,valid_data_loader,num_epochs=20,learning_rate=0.005)

# Best Bert
best_modelsenti = SentimentClassifierPooled(30,2)
best_modelsenti.cuda()
best_modelsenti.load_state_dict(torch.load('/content/drive/My Drive/ColabNotebooks/new/bestmodel=model_epoch158217.pt'))

device = "cuda" if torch.cuda.is_available() else "cpu"
model = best_modelsenti.to(device)
# Test Accuracy
test_accuracy = get_accuracy(model, test_data_loader, device=device)
print("Test Accuracy:", test_accuracy)
# F1 score
test_f1_score = get_f1_score(model, test_data_loader, device=device)
print("Test F1 Score:", test_f1_score)

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# jupyter nbconvert --execute --to html /content/ECE1513Project.ipynb